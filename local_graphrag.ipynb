{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "161b8161-c1b6-413c-a62b-17d21b298687",
      "cell_type": "markdown",
      "source": "# Steg 1 — Installera nödvändiga bibliotek",
      "metadata": {}
    },
    {
      "id": "beb3e581-a70e-4949-beeb-e26de1bf1627",
      "cell_type": "code",
      "source": "!pip install py2neo llama_index llama_index.llms.ollama llama_index.embeddings.ollama",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "299bcf7c-96aa-4a29-9d14-efd6787aeafe",
      "cell_type": "markdown",
      "source": "# Steg 2 — Anslut till Neo4j",
      "metadata": {}
    },
    {
      "id": "ff25b26d-dbc8-4d09-950f-34ef73e9b925",
      "cell_type": "code",
      "source": "from py2neo import Graph\n\ngraph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2b23a539-1286-4214-aed8-726b713822c1",
      "cell_type": "markdown",
      "source": "# Steg 3 — Definiera en enkel chunking-funktion",
      "metadata": {}
    },
    {
      "id": "2aa1bd3d-cc32-489f-a3b0-9e5d8d3a6a6f",
      "cell_type": "code",
      "source": "def chunk_text(text, max_tokens=300):\n    \"\"\"Väldigt enkel chunking: splittar på meningar.\"\"\"\n    sentences = text.split('. ')\n    chunks, current_chunk = [], \"\"\n    for sentence in sentences:\n        if len(current_chunk) + len(sentence) < max_tokens:\n            current_chunk += sentence + '. '\n        else:\n            chunks.append(current_chunk.strip())\n            current_chunk = sentence + '. '\n    if current_chunk:\n        chunks.append(current_chunk.strip())\n    return chunks",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6b7d5479-fb7d-41cd-9322-808c532ed5cd",
      "cell_type": "markdown",
      "source": "# Steg 4 — Ladda in ett testdokument",
      "metadata": {}
    },
    {
      "id": "85d305d3-f966-4295-b5d5-11413aeaef8e",
      "cell_type": "code",
      "source": "test_document = \"\"\"\nGDPR är en europeisk lag som syftar till att stärka individens rättigheter vid behandling av personuppgifter.\nAlla företag måste följa GDPR för att säkerställa integritet och transparens. \nBrott mot GDPR kan leda till höga böter. \nDataskyddsombud ansvarar för efterlevnad av reglerna.\n\"\"\"\nchunks = chunk_text(test_document)\nchunks",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e9c846df-3ab0-4c29-b67d-8e5758c6a643",
      "cell_type": "markdown",
      "source": "# Steg 5 — Generera embeddings",
      "metadata": {}
    },
    {
      "id": "246c69a3-5000-40ba-ba6e-3eb1942fcdc9",
      "cell_type": "code",
      "source": "from llama_index.embeddings.ollama import OllamaEmbedding\n\nembed_model = OllamaEmbedding(model_name=\"mistral\")\n\nembedded_chunks = [(chunk, embed_model.get_text_embedding(chunk)) for chunk in chunks]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e68e08de-eb73-4c28-9c97-78857c798b24",
      "cell_type": "markdown",
      "source": "# Steg 6 — Lagra chunks i Neo4j",
      "metadata": {}
    },
    {
      "id": "ffdb77ba-a026-45ae-bc54-1174fb410278",
      "cell_type": "code",
      "source": "for chunk_text, embedding in embedded_chunks:\n    graph.run(\"\"\"\n    CREATE (c:Chunk {text: $text, embedding: $embedding})\n    \"\"\", text=chunk_text, embedding=embedding)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "044c6e7a-bfed-42ca-964e-2c9a62de14fd",
      "cell_type": "code",
      "source": "#✅ Nu är din dokumentinformation inmatad i grafen!",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "71869a92-6519-4326-ab42-9bee482de34e",
      "cell_type": "markdown",
      "source": "# Steg 7 — Sök i grafen via embeddings",
      "metadata": {}
    },
    {
      "id": "f557a4bd-b60d-4c03-a49a-cffe1d1bea21",
      "cell_type": "code",
      "source": "query = \"Vad handlar GDPR om?\"\nquery_embedding = embed_model.get_text_embedding(query)\n\nresults = graph.run(\"\"\"\n    MATCH (c:Chunk)\n    WITH c, gds.similarity.cosine(c.embedding, $query_embedding) AS score\n    WHERE score > 0.7\n    RETURN c.text AS text, score\n    ORDER BY score DESC\n    LIMIT 5\n\"\"\", query_embedding=query_embedding).data()\n\nresults",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "29fe5e3b-b4fc-4832-bf55-7b6e9feda14d",
      "cell_type": "markdown",
      "source": "# Steg 8 — Bygg upp en prompt från träffarna",
      "metadata": {}
    },
    {
      "id": "eed2f00c-821d-4a9d-8379-e29421cfb304",
      "cell_type": "code",
      "source": "context = \"\\n\\n\".join([r['text'] for r in results])\n\nprompt = f\"\"\"Context:\n{context}\n\nAnswer the question:\n{query}\n\"\"\"\nprint(prompt)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "36ba7a3f-87fa-4bd3-854c-498e16e50420",
      "cell_type": "markdown",
      "source": "# Steg 9 — Anropa LLM för att svara på frågan",
      "metadata": {}
    },
    {
      "id": "81b525e9-c336-470e-90de-ff3098f251b7",
      "cell_type": "code",
      "source": "from llama_index.llms.ollama import Ollama\n\nllm = Ollama(model=\"mistral\")\n\nresponse = llm.complete(prompt)\nprint(response.text)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3a2155ef-d9ee-4504-a59b-8d6ac11eb481",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}